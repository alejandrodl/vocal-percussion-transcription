{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Parameters\n",
    "\n",
    "modes = ['vae','classall','classred','syllall','syllred','phonall','phonred','siamese'] # Triplet!!\n",
    "#clfs = ['slp','mlp','logr','knn','rf','xgboost']#\n",
    "clfs = ['knn']\n",
    "\n",
    "list_test_participants_avp = [8,10,18,23]\n",
    "list_test_participants_lvt = [0,6,7,13]\n",
    "\n",
    "# Calculate utterance-wise weights\n",
    "\n",
    "num_test_utterances = []\n",
    "for part in list_test_participants_avp:\n",
    "    if part<=9:\n",
    "        test_dataset = np.load('../../data/interim/AVP/Dataset_Test_0' + str(part) + '.npy')\n",
    "    else:\n",
    "        test_dataset = np.load('../../data/interim/AVP/Dataset_Test_' + str(part) + '.npy')\n",
    "    num_test_utterances.append(test_dataset.shape[0])\n",
    "for part in list_test_participants_lvt:\n",
    "    if part<=9:\n",
    "        test_dataset = np.load('../../data/interim/LVT/Dataset_Test_0' + str(part) + '.npy')\n",
    "    else:\n",
    "        test_dataset = np.load('../../data/interim/LVT/Dataset_Test_' + str(part) + '.npy')\n",
    "    num_test_utterances.append(test_dataset.shape[0])\n",
    "utterance_wise_weights = num_test_utterances/np.sum(np.array(num_test_utterances))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Results\n",
    "\n",
    "for b in range(len(modes)):\n",
    "\n",
    "    for c in range(len(clfs)):\n",
    "\n",
    "        mode = modes[b]\n",
    "        clf = clfs[c]\n",
    "\n",
    "        accuracies_raw = np.load('../../results/' + mode + '/accuracies.npy')\n",
    "        accuracies_mean = np.mean(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        accuracies_std = np.std(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        \n",
    "        print([mode,clf])\n",
    "        print([accuracies_mean[0],accuracies_std[0]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['vae', 'knn']\n",
      "[0.7910309827280464, 0.01624331950467861]\n",
      "['class', 'knn']\n",
      "[0.7988555147232376, 0.022928629687180183]\n",
      "['syllall', 'knn']\n",
      "[0.8896069759332862, 0.014638511095622024]\n",
      "['syllred', 'knn']\n",
      "[0.8844865828108878, 0.02379058000055109]\n",
      "['phonall', 'knn']\n",
      "[0.8765230289629609, 0.01855451173206599]\n",
      "['phonred', 'knn']\n",
      "[0.8635369357898576, 0.015212323426247776]\n",
      "['siamese', 'knn']\n",
      "[0.8642709503450103, 0.025331657417954904]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Results Utterance-Wise\n",
    "\n",
    "for b in range(len(modes)):\n",
    "\n",
    "    for c in range(len(clfs)):\n",
    "\n",
    "        mode = modes[b]\n",
    "        clf = clfs[c]\n",
    "\n",
    "        accuracies_raw = np.load('../../results/' + mode + '/accuracies.npy')\n",
    "\n",
    "        for i in range(accuracies_raw.shape[0]):\n",
    "            for j in range(accuracies_raw.shape[1]):\n",
    "                for k in range(accuracies_raw.shape[2]):\n",
    "                    accuracies_raw[i,j,k] *= utterance_wise_weights*8\n",
    "\n",
    "        accuracies_mean = np.mean(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        accuracies_std = np.std(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        \n",
    "        print([mode,clf])\n",
    "        print([accuracies_mean[0],accuracies_std[0]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['eng_mfcc_env', 'knn']\n",
      "[0.810702875399361, 0.0]\n",
      "['vae', 'knn']\n",
      "[0.7723642172523961, 0.024009536836821766]\n",
      "['class', 'knn']\n",
      "[0.7736421725239616, 0.015443244777772473]\n",
      "['syllall', 'knn']\n",
      "[0.8630990415335462, 0.017131424180562703]\n",
      "['syllred', 'knn']\n",
      "[0.859185303514377, 0.03127086060771459]\n",
      "['phonall', 'knn']\n",
      "[0.8460063897763577, 0.024275894840729593]\n",
      "['phonred', 'knn']\n",
      "[0.8334664536741213, 0.02157806402161614]\n",
      "['siamese', 'knn']\n",
      "[0.8297124600638976, 0.032210985573016736]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "interpreter": {
   "hash": "d27af43fe1451b594071d7eb39c022d87d8cdc22e728ecc3a021ec050d61a923"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}