{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Parameters\n",
    "\n",
    "modes = ['vae','classall','classred','syllall','syllred','phonall','phonred','siamese'] # Triplet!!\n",
    "#clfs = ['slp','mlp','logr','knn','rf','xgboost']#\n",
    "clfs = ['knn']\n",
    "\n",
    "list_test_participants_avp = [8,10,18,23]\n",
    "list_test_participants_lvt = [0,6,7,13]\n",
    "\n",
    "# Calculate utterance-wise weights\n",
    "\n",
    "num_test_utterances = []\n",
    "for part in list_test_participants_avp:\n",
    "    if part<=9:\n",
    "        test_dataset = np.load('../../data/interim/AVP/Dataset_Test_0' + str(part) + '.npy')\n",
    "    else:\n",
    "        test_dataset = np.load('../../data/interim/AVP/Dataset_Test_' + str(part) + '.npy')\n",
    "    num_test_utterances.append(test_dataset.shape[0])\n",
    "for part in list_test_participants_lvt:\n",
    "    if part<=9:\n",
    "        test_dataset = np.load('../../data/interim/LVT/Dataset_Test_0' + str(part) + '.npy')\n",
    "    else:\n",
    "        test_dataset = np.load('../../data/interim/LVT/Dataset_Test_' + str(part) + '.npy')\n",
    "    num_test_utterances.append(test_dataset.shape[0])\n",
    "utterance_wise_weights = num_test_utterances/np.sum(np.array(num_test_utterances))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Results\n",
    "\n",
    "for b in range(len(modes)):\n",
    "\n",
    "    for c in range(len(clfs)):\n",
    "\n",
    "        mode = modes[b]\n",
    "        clf = clfs[c]\n",
    "\n",
    "        accuracies_raw = np.load('../../results/' + mode + '/accuracies.npy')\n",
    "        accuracies_mean = np.mean(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        accuracies_std = np.std(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        \n",
    "        print([mode,clf])\n",
    "        print([accuracies_mean[0],accuracies_std[0]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['vae', 'knn']\n",
      "[0.7730113438870969, 0.023887072282731424]\n",
      "['classall', 'knn']\n",
      "[0.7858345558020263, 0.024357586246602406]\n",
      "['classred', 'knn']\n",
      "[0.741238013089875, 0.039757954343512675]\n",
      "['syllall', 'knn']\n",
      "[0.8742735089334246, 0.022817869833435873]\n",
      "['syllred', 'knn']\n",
      "[0.854391218665137, 0.028331635789420072]\n",
      "['phonall', 'knn']\n",
      "[0.8593127258705074, 0.02590090231384071]\n",
      "['phonred', 'knn']\n",
      "[0.8654163737664936, 0.026183922613394025]\n",
      "['siamese', 'knn']\n",
      "[0.8492785796940214, 0.02143377960096325]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Results Utterance-Wise\n",
    "\n",
    "for b in range(len(modes)):\n",
    "\n",
    "    for c in range(len(clfs)):\n",
    "\n",
    "        mode = modes[b]\n",
    "        clf = clfs[c]\n",
    "\n",
    "        accuracies_raw = np.load('../../results/' + mode + '/accuracies.npy')\n",
    "\n",
    "        for i in range(accuracies_raw.shape[0]):\n",
    "            for j in range(accuracies_raw.shape[1]):\n",
    "                for k in range(accuracies_raw.shape[2]):\n",
    "                    accuracies_raw[i,j,k] *= utterance_wise_weights*8\n",
    "\n",
    "        accuracies_mean = np.mean(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        accuracies_std = np.std(np.mean(np.mean(accuracies_raw,axis=-1),axis=-1),axis=-1)\n",
    "        \n",
    "        print([mode,clf])\n",
    "        print([accuracies_mean[0],accuracies_std[0]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['vae', 'knn']\n",
      "[0.7826677316293928, 0.02838431601115306]\n",
      "['classall', 'knn']\n",
      "[0.7687699680511182, 0.02727434048270364]\n",
      "['classred', 'knn']\n",
      "[0.7106230031948881, 0.03483389746174469]\n",
      "['syllall', 'knn']\n",
      "[0.846884984025559, 0.02841037584123069]\n",
      "['syllred', 'knn']\n",
      "[0.829552715654952, 0.03798794594061579]\n",
      "['phonall', 'knn']\n",
      "[0.8304313099041533, 0.031734604919298866]\n",
      "['phonred', 'knn']\n",
      "[0.8359424920127794, 0.03104389180771539]\n",
      "['siamese', 'knn']\n",
      "[0.819408945686901, 0.01384556500486244]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "interpreter": {
   "hash": "d27af43fe1451b594071d7eb39c022d87d8cdc22e728ecc3a021ec050d61a923"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}