{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.interpolate\n",
    "import scipy.io.wavfile\n",
    "import sys\n",
    "import logging\n",
    "import aubio\n",
    "import librosa\n",
    "from librosa.util import frame\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pdb\n",
    "import random\n",
    "from random import randrange\n",
    "import shutil\n",
    "import copy\n",
    "#import rubberband\n",
    "import pyrubberband as pyrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Separate function\n",
    "\n",
    "def Load_Train_Data_AVP(Dataset, Classes, Change_Part, N):\n",
    "\n",
    "    Change_Part = Change_Part.astype(int)\n",
    "\n",
    "    if N==len(Change_Part)-1:\n",
    "        Dataset_Train = np.vstack((Dataset[:sum(Change_Part[:N])],Dataset[sum(Change_Part):]))\n",
    "        Classes_Train = np.concatenate((Classes[:sum(Change_Part[:N])],Classes[sum(Change_Part):]))\n",
    "    else:\n",
    "        Dataset_Train = np.vstack((Dataset[:sum(Change_Part[:N])],Dataset[sum(Change_Part[:N+1]):]))\n",
    "        Classes_Train = np.concatenate((Classes[:sum(Change_Part[:N])],Classes[sum(Change_Part[:N+1]):]))\n",
    "        \n",
    "    return Dataset_Train, Classes_Train\n",
    "\n",
    "\n",
    "def Load_Test_Data_AVP(Dataset, Classes, Change_Part, N):\n",
    "\n",
    "    Change_Part = Change_Part.astype(int)\n",
    "    \n",
    "    if N==len(Change_Part)-1:\n",
    "        Dataset_Train = Dataset[int(sum(Change_Part[:N])):]\n",
    "        Classes_Train = Classes[int(sum(Change_Part[:N])):]\n",
    "    else:\n",
    "        Dataset_Train = Dataset[int(sum(Change_Part[:N])):int(sum(Change_Part[:N+1]))]\n",
    "        Classes_Train = Classes[int(sum(Change_Part[:N])):int(sum(Change_Part[:N+1]))]\n",
    "        \n",
    "    return Dataset_Train, Classes_Train'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes):\n",
    "\n",
    "    Onset_Phonemes_Labels = np.zeros(Onset_Phonemes.shape)\n",
    "    for n in range(len(Onset_Phonemes)):\n",
    "        if 'ts' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 0\n",
    "        elif 'tʃ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 1\n",
    "        elif 'tɕ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 2\n",
    "        elif 'kg' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 3\n",
    "        elif 'tʒ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 4\n",
    "        elif 'ʡʢ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 5\n",
    "        elif 'dʒ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 6\n",
    "        elif 'kʃ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Labels[n] = 7\n",
    "        elif Onset_Phonemes[n]=='t':\n",
    "            Onset_Phonemes_Labels[n] = 8\n",
    "        elif Onset_Phonemes[n]=='p':\n",
    "            Onset_Phonemes_Labels[n] = 9\n",
    "        elif Onset_Phonemes[n]=='k':\n",
    "            Onset_Phonemes_Labels[n] = 10\n",
    "        elif Onset_Phonemes[n]=='s':\n",
    "            Onset_Phonemes_Labels[n] = 11\n",
    "        elif Onset_Phonemes[n]=='!':\n",
    "            Onset_Phonemes_Labels[n] = 12\n",
    "            \n",
    "    Nucleus_Phonemes_Labels = np.zeros(Nucleus_Phonemes.shape)\n",
    "    for n in range(len(Nucleus_Phonemes)):\n",
    "        if 'a' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 0\n",
    "        elif 'e' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 1\n",
    "        elif 'i' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 2\n",
    "        elif 'o' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 3\n",
    "        elif 'u' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 4\n",
    "        elif 'æ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 5\n",
    "        elif 'œ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 6\n",
    "        elif 'ə' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 7\n",
    "        elif 'ʊ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 8\n",
    "        elif 'ɯ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 9\n",
    "        elif 'y' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 10\n",
    "        elif 'ɪ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 11\n",
    "        elif 'ɐ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 12\n",
    "        elif 'ʌ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 13\n",
    "        elif 'h' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Labels[n] = 14\n",
    "        else:\n",
    "            Nucleus_Phonemes_Labels[n] = 15\n",
    "               \n",
    "    Onset_Phonemes_Reduced_Labels = np.zeros(Onset_Phonemes.shape)\n",
    "    for n in range(len(Onset_Phonemes)):\n",
    "        if 'ts' in Onset_Phonemes[n] or Onset_Phonemes[n]=='s':\n",
    "            Onset_Phonemes_Reduced_Labels[n] = 0\n",
    "        elif 'tʃ' in Onset_Phonemes[n] or 'tɕ' in Onset_Phonemes[n] or 'dʒ' in Onset_Phonemes[n] or 'tʒ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Reduced_Labels[n] = 1\n",
    "        elif 'kg' in Onset_Phonemes[n] or Onset_Phonemes[n]=='k' or 'kʃ' in Onset_Phonemes[n]:\n",
    "            Onset_Phonemes_Reduced_Labels[n] = 2\n",
    "        elif 'ʡʢ' in Onset_Phonemes[n] or Onset_Phonemes[n]=='p':\n",
    "            Onset_Phonemes_Reduced_Labels[n] = 3\n",
    "        elif Onset_Phonemes[n]=='t' or Onset_Phonemes[n]=='!':\n",
    "            Onset_Phonemes_Reduced_Labels[n] = 4\n",
    "            \n",
    "    Nucleus_Phonemes_Reduced_Labels = np.zeros(Nucleus_Phonemes.shape)\n",
    "    for n in range(len(Nucleus_Phonemes)):\n",
    "        if 'a' in Nucleus_Phonemes[n] or 'æ' in Nucleus_Phonemes[n] or 'ɐ' in Nucleus_Phonemes[n] or 'ʌ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 0\n",
    "        elif 'e' in Nucleus_Phonemes[n] or 'œ' in Nucleus_Phonemes[n] or 'ə' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 1\n",
    "        elif 'i' in Nucleus_Phonemes[n] or 'y' in Nucleus_Phonemes[n] or 'ɪ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 2\n",
    "        elif 'o' in Nucleus_Phonemes[n] or 'ʊ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 3\n",
    "        elif 'u' in Nucleus_Phonemes[n] or 'ɯ' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 4\n",
    "        elif 'h' in Nucleus_Phonemes[n]:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 5\n",
    "        else:\n",
    "            Nucleus_Phonemes_Reduced_Labels[n] = 6\n",
    "            \n",
    "    return Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def pitch_shift(data, sampling_rate, pitch_factor):\n",
    "    #return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "#def time_stretch(data, stretch_factor):\n",
    "    #return librosa.effects.time_stretch(data, stretch_factor)\n",
    "\n",
    "#def time_stretch(data, stretch_factor):\n",
    "    #return rubberband.stretch(data, rate=44100, ratio=stretch_factor, crispness=6, formants=False, precise=True)\n",
    "    \n",
    "def pitch_shift(data, sampling_rate, pitch_semitones):\n",
    "    return pyrb.pitch_shift(data, sampling_rate, pitch_semitones)\n",
    "\n",
    "def time_stretch(data, stretch_factor):\n",
    "    return pyrb.time_stretch(data, 44100, stretch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''audio, fs = sf.read('audio_ref.wav')\n",
    "audio_shifted = pitch_shift(audio, 44100, 1)\n",
    "sf.write('audio_pitch_up.wav', audio_shifted, 44100)\n",
    "audio_shifted = pitch_shift(audio, 44100, -1)\n",
    "sf.write('audio_pitch_down.wav', audio_shifted, 44100)\n",
    "#audio_shifted = time_stretch(audio, 1.15)\n",
    "#sf.write('audio_stretch_up.wav', audio_shifted, 44100)\n",
    "audio_shifted = time_stretch_py(audio, 1.15)\n",
    "sf.write('audio_stretch_py_up.wav', audio_shifted, 44100)\n",
    "#audio_shifted = time_stretch(audio, 0.85)\n",
    "#sf.write('audio_stretch_down.wav', audio_shifted, 44100)\n",
    "audio_shifted = time_stretch_py(audio, 0.85)\n",
    "sf.write('audio_stretch_py_down.wav', audio_shifted, 44100)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets = ['AVP_Personal_TRAIN_AUG_','AVP_Fixed_Small','LVT_2','LVT_3','BTX','VIM']\n",
    "\n",
    "frame_sizes = [1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_size = 689\n",
    "delta_bool = False\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AVP Test Dataset\n",
    "\n",
    "path_audio = '../../AVP_Dataset/Personal'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "list_wav = list_wav[2::5]\n",
    "list_csv = list_csv[2::5]\n",
    "\n",
    "for i in range(len(list_wav)):\n",
    "\n",
    "    onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "    Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "    Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "    Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "    Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "    audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "    audio = audio/np.max(abs(audio))\n",
    "\n",
    "    onsets_samples = onsets*fs\n",
    "    onsets_samples = onsets_samples.astype(int)\n",
    "    \n",
    "    for j in range(len(num_specs)):\n",
    "        \n",
    "        for k in range(len(frame_sizes)):\n",
    "        \n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            \n",
    "            '''spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            if delta_bool:\n",
    "                delta = librosa.feature.delta(spec)\n",
    "                Dataset_Spec = np.concatenate((spec, delta), axis=1)\n",
    "            else:\n",
    "                Dataset_Spec = spec\n",
    "\n",
    "            Onsets = np.zeros(spec.shape[0])\n",
    "            location = np.floor(onsets_samples/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "                    \n",
    "            list_num = [Spec_Matrix.shape[0],len(Classes),len(Onset_Phonemes_Labels),len(Nucleus_Phonemes_Labels),len(Onset_Phonemes_Reduced_Labels),len(Nucleus_Phonemes_Reduced_Labels)]\n",
    "            if list_num.count(list_num[0])!=len(list_num):\n",
    "                print(list_num)\n",
    "                print(list_wav[i])\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Test_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_AVP/Classes_Test_0' + str(i), Classes)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Test_0' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Test_0' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Test_0' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Test_0' + str(i), Nucleus_Phonemes_Reduced_Labels)\n",
    "            else:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Test_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_AVP/Classes_Test_' + str(i), Classes)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Test_' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Test_' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Test_' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Test_' + str(i), Nucleus_Phonemes_Reduced_Labels)'''\n",
    "            \n",
    "    audio = np.concatenate((audio,np.zeros(4096)))\n",
    "\n",
    "    audios_all = []\n",
    "    for osm in range(len(onsets_samples)-1):\n",
    "        audios_all.append(audio[onsets_samples[osm]:onsets_samples[osm+1]])\n",
    "    audios_all.append(audio[onsets_samples[osm+1]:])\n",
    "\n",
    "    if i<=9:\n",
    "        np.save('../_Data/UC_AVP_Audio/Dataset_Test_0' + str(i), np.array(audios_all))\n",
    "    else:\n",
    "        np.save('../_Data/UC_AVP_Audio/Dataset_Test_' + str(i), np.array(audios_all))\n",
    "\n",
    "    if i==0:\n",
    "        for pl in range(10):\n",
    "            plt.figure()\n",
    "            plt.plot(np.array(audios_all[pl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_AVP/Dataset_Test_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_AVP/Classes_Test_0' + str(i) + '.npy')\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AVP Test Aug Dataset\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]\n",
    "\n",
    "path_audio = '../../AVP_Dataset/Personal'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "list_wav = list_wav[2::5]\n",
    "list_csv = list_csv[2::5]\n",
    "\n",
    "for i in range(len(list_wav)):\n",
    "\n",
    "    onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "    Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "    \n",
    "    audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "    audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "    onsets_samples = onsets*fs\n",
    "    onsets_ref = onsets_samples.astype(int)\n",
    "    \n",
    "    for j in range(len(num_specs)):\n",
    "        \n",
    "        for k in range(len(frame_sizes)):\n",
    "        \n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "            \n",
    "                spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                if delta_bool:\n",
    "                    delta = librosa.feature.delta(spec)\n",
    "                    Dataset_Spec = np.concatenate((spec, delta), axis=1)\n",
    "                else:\n",
    "                    Dataset_Spec = spec\n",
    "\n",
    "                Onsets = np.zeros(spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                if num_onsets!=len(Classes):\n",
    "                    raise('num_onsets==len(Classes)')\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "                        \n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "                \n",
    "                list_num = [Spec_Matrix_All.shape[0],len(Classes_All),len(Onset_Phonemes_Labels_All),len(Nucleus_Phonemes_Labels_All),len(Onset_Phonemes_Reduced_Labels_All),len(Nucleus_Phonemes_Reduced_Labels_All)]\n",
    "                if list_num.count(list_num[0])!=len(list_num):\n",
    "                    print(list_num)\n",
    "                    print(list_wav[i])\n",
    "            \n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:]\n",
    "            \n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Test_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_AVP/Classes_Test_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Test_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Test_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Test_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Test_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Test_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_AVP/Classes_Test_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Test_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Test_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Test_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Test_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_AVP/Dataset_Test_Aug_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_AVP/Classes_Test_Aug_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train Dataset\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]\n",
    "\n",
    "fs = 44100\n",
    "\n",
    "path_audio = '../../AVP_Dataset/Personal'\n",
    "\n",
    "list_wav_all = []\n",
    "list_csv_all = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav_all.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv_all.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav_all = sorted(list_wav_all)\n",
    "list_csv_all = sorted(list_csv_all)\n",
    "\n",
    "list_wav_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "list_wav = list_wav_all[::5] + list_wav_all[1::5] + list_wav_all[3::5] + list_wav_all[4::5]\n",
    "list_csv = list_csv_all[::5] + list_csv_all[1::5] + list_csv_all[3::5] + list_csv_all[4::5]\n",
    "\n",
    "list_wav_all = sorted(list_wav)\n",
    "list_csv_all = sorted(list_csv)\n",
    "\n",
    "list_wav_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "\n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "        \n",
    "        for part in range(28):\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "\n",
    "            for i in range(4):\n",
    "\n",
    "                onsets = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=0)\n",
    "                Classes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav_all[4*part+i], sr=44100)\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets_ref = onsets_samples.astype(int)\n",
    "                \n",
    "                for k in range(1):\n",
    "\n",
    "                    Classes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                    Onset_Phonemes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                    Nucleus_Phonemes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                    Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                    if k==0:\n",
    "                        audio = audio_ref.copy()\n",
    "                        onsets = onsets_ref.copy()\n",
    "\n",
    "                    spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "                    \n",
    "                    if delta_bool:\n",
    "                        delta = librosa.feature.delta(spec)\n",
    "                        Dataset_Spec = np.concatenate((spec, delta), axis=1)\n",
    "                    else:\n",
    "                        Dataset_Spec = spec\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    if Onsets[len(Onsets)-1]==1:\n",
    "                        Classes = Classes[:-1]\n",
    "                        Onsets[len(Onsets)-1] = 0\n",
    "                        print(len(Classes))\n",
    "                        print(int(np.sum(Onsets)))\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    if num_onsets!=len(Classes):\n",
    "                        raise('num_onsets!=len(Classes)')\n",
    "                    Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            c = 1\n",
    "                            while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix[count] = Spec\n",
    "                            count += 1\n",
    "\n",
    "                    if Spec_Matrix.shape[0]==Classes.shape[0]:\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                        Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                        Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                        Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                        Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                        Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "                    else:\n",
    "                        print('Cuidao')\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                        Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                        Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                        Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                        Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                        Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:]        \n",
    "\n",
    "            if part<=9:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Train_0' + str(part) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_AVP/Classes_Train_0' + str(part), Classes_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Train_0' + str(part), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Train_0' + str(part), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Train_0' + str(part), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Train_0' + str(part), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Train_' + str(part) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_AVP/Classes_Train_' + str(part), Classes_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Train_' + str(part), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Train_' + str(part), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Train_' + str(part), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Train_' + str(part), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_AVP/Dataset_Train_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_AVP/Classes_Train_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/alejandrodelgadoluezas/anaconda3/envs/mip/lib/python3.6/site-packages/ipykernel_launcher.py:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# Create Train Aug Dataset\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]\n",
    "\n",
    "fs = 44100\n",
    "\n",
    "path_audio = '../../AVP_Dataset/Personal'\n",
    "\n",
    "list_wav_all = []\n",
    "list_csv_all = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav_all.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv_all.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav_all = sorted(list_wav_all)\n",
    "list_csv_all = sorted(list_csv_all)\n",
    "\n",
    "list_wav_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "list_wav = list_wav_all[::5] + list_wav_all[1::5] + list_wav_all[3::5] + list_wav_all[4::5]\n",
    "list_csv = list_csv_all[::5] + list_csv_all[1::5] + list_csv_all[3::5] + list_csv_all[4::5]\n",
    "\n",
    "list_wav_all = sorted(list_wav)\n",
    "list_csv_all = sorted(list_csv)\n",
    "\n",
    "list_wav_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv_all.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "for j in range(1):\n",
    "\n",
    "    for k in range(1):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "        \n",
    "        for part in range(28):\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "\n",
    "            for i in range(4):\n",
    "\n",
    "                onsets = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=0)\n",
    "                Classes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav_all[4*part+i], sr=44100)\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets_ref = onsets_samples.astype(int)\n",
    "                \n",
    "                audios_all = []\n",
    "                \n",
    "                for k in range(10):\n",
    "\n",
    "                    Classes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                    Onset_Phonemes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                    Nucleus_Phonemes = np.loadtxt(list_csv_all[4*part+i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                    Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                    kn = np.random.randint(0,2)\n",
    "                    pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                    st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                    if kn==0:\n",
    "                        audio = pitch_shift(audio_ref, fs, pt)\n",
    "                        audio = time_stretch(audio, st)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "                    elif kn==1:\n",
    "                        audio = time_stretch(audio_ref, st)\n",
    "                        audio = pitch_shift(audio, fs, pt)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "\n",
    "                    '''spec = librosa.feature.melspectrogram(np.concatenate((audio,np.zeros(4096))), sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "                    \n",
    "                    if delta_bool:\n",
    "                        delta = librosa.feature.delta(spec)\n",
    "                        Dataset_Spec = np.concatenate((spec, delta), axis=1)\n",
    "                    else:\n",
    "                        Dataset_Spec = spec\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    if Onsets[len(Onsets)-1]==1:\n",
    "                        Classes = Classes[:-1]\n",
    "                        Onsets[len(Onsets)-1] = 0\n",
    "                        print(len(Classes))\n",
    "                        print(int(np.sum(Onsets)))\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    if num_onsets!=len(Classes):\n",
    "                        raise('num_onsets!=len(Classes)')\n",
    "                    Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            c = 1\n",
    "                            while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix[count] = Spec\n",
    "                            count += 1\n",
    "\n",
    "                    list_num = [Spec_Matrix_All.shape[0],len(Classes_All),len(Onset_Phonemes_Labels_All),len(Nucleus_Phonemes_Labels_All),len(Onset_Phonemes_Reduced_Labels_All),len(Nucleus_Phonemes_Reduced_Labels_All)]\n",
    "                    if list_num.count(list_num[0])==len(list_num):\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                        Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                        Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                        Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                        Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                        Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "                    else:\n",
    "                        print(list_num)\n",
    "                        print(list_wav[i])'''\n",
    "                    \n",
    "                    audio = np.concatenate((audio,np.zeros(4096)))\n",
    "            \n",
    "                    for osm in range(len(onsets)-1):\n",
    "                        audios_all.append(audio[onsets[osm]:onsets[osm+1]])\n",
    "                    audios_all.append(audio[onsets[osm+1]:])\n",
    "\n",
    "            '''Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:]       \n",
    "\n",
    "            if part<=9:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Train_Aug_0' + str(part) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_AVP/Classes_Train_Aug_0' + str(part), Classes_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Train_Aug_0' + str(part), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Train_Aug_0' + str(part), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Train_Aug_0' + str(part), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Train_Aug_0' + str(part), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_AVP/Dataset_Train_Aug_' + str(part) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_AVP/Classes_Train_Aug_' + str(part), Classes_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Train_Aug_' + str(part), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Train_Aug_' + str(part), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Onset_Reduced_Train_Aug_' + str(part), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_AVP/Syll_Nucleus_Reduced_Train_Aug_' + str(part), Nucleus_Phonemes_Reduced_Labels_All)'''\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_AVP_Audio/Dataset_Train_0' + str(part), np.array(audios_all))\n",
    "            else:\n",
    "                np.save('../_Data/UC_AVP_Audio/Dataset_Train_' + str(part), np.array(audios_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_AVP/Dataset_Train_Aug_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_AVP/Classes_Train_Aug_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BTX Dataset\n",
    "\n",
    "frame_sizes = [256,512,1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_sizes = [220,413]\n",
    "delta_bool = False\n",
    "\n",
    "Dataset_Str = 'BTX'\n",
    "\n",
    "path_audio = '../../Beatbox_Set'\n",
    "\n",
    "list_wav = []\n",
    "list_csv_1 = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv_1.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv_1[:14])\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "                Classes_All = np.zeros(1)\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                Classes = []\n",
    "                labels = np.genfromtxt(list_csv[i], dtype='S', delimiter=',', usecols=1).tolist()\n",
    "                for h in range(len(labels)):\n",
    "                    Classes.append(labels[h].decode(\"utf-8\"))\n",
    "                Classes = np.array(Classes)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                audio = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets = onsets_samples.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                if Onsets[len(Onsets)-1]==1:\n",
    "                    Classes = Classes[:-1]\n",
    "                if Onsets[len(Onsets)-1]==1:\n",
    "                    Onsets[len(Onsets)-1] = 0\n",
    "                    print(len(Classes))\n",
    "                    print(int(np.sum(Onsets)))\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                if num_onsets!=len(Classes):\n",
    "                    raise('num_onsets!=len(Classes)')\n",
    "                Spec_Matrix = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                cc = 0\n",
    "                Classes_Select = []\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        if Classes[cc]=='k' or Classes[cc]=='hc' or Classes[cc]=='ho' or Classes[cc]=='sb' or Classes[cc]=='sk' or Classes[cc]=='s':\n",
    "                            Classes_Select.append(Classes[cc])\n",
    "                            c = 1\n",
    "                            while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix = np.vstack((Spec_Matrix,np.expand_dims(Spec,axis=0)))\n",
    "                            count += 1\n",
    "                        cc += 1\n",
    "\n",
    "                Spec_Matrix = Spec_Matrix[1:]\n",
    "\n",
    "                if i<=9:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_0' + str(i) + '_' + str(hop_size), Classes_Select)\n",
    "                else:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_' + str(i) + '_' + str(hop_size), Classes_Select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BTX Dataset (but with the typical 689 of hop size)\n",
    "\n",
    "frame_sizes = [1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_sizes = [689]\n",
    "delta_bool = False\n",
    "\n",
    "Dataset_Str = 'BTX'\n",
    "\n",
    "path_audio = '../../Beatbox_Set'\n",
    "\n",
    "list_wav = []\n",
    "list_csv_1 = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv_1.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv_1[:14])\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "                Classes_All = np.zeros(1)\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                Classes = []\n",
    "                labels = np.genfromtxt(list_csv[i], dtype='S', delimiter=',', usecols=1).tolist()\n",
    "                for h in range(len(labels)):\n",
    "                    Classes.append(labels[h].decode(\"utf-8\"))\n",
    "                Classes = np.array(Classes)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                audio = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets = onsets_samples.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                if Onsets[len(Onsets)-1]==1:\n",
    "                    Classes = Classes[:-1]\n",
    "                if Onsets[len(Onsets)-1]==1:\n",
    "                    Onsets[len(Onsets)-1] = 0\n",
    "                    print(len(Classes))\n",
    "                    print(int(np.sum(Onsets)))\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                if num_onsets!=len(Classes):\n",
    "                    raise('num_onsets!=len(Classes)')\n",
    "                Spec_Matrix = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                cc = 0\n",
    "                Classes_Select = []\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        if Classes[cc]=='k' or Classes[cc]=='hc' or Classes[cc]=='ho' or Classes[cc]=='sb' or Classes[cc]=='sk' or Classes[cc]=='s':\n",
    "                            Classes_Select.append(Classes[cc])\n",
    "                            c = 1\n",
    "                            while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix = np.vstack((Spec_Matrix,np.expand_dims(Spec,axis=0)))\n",
    "                            count += 1\n",
    "                        cc += 1\n",
    "\n",
    "                Spec_Matrix = Spec_Matrix[1:]\n",
    "\n",
    "                if i<=9:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_0' + str(i), Classes_Select)\n",
    "                else:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_' + str(i), Classes_Select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_BTX/Dataset_BTX_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_BTX/Classes_BTX_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BTX Aug Dataset\n",
    "\n",
    "frame_sizes = [256,512,1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_sizes = [220,413]\n",
    "delta_bool = False\n",
    "\n",
    "Dataset_Str = 'BTX'\n",
    "\n",
    "path_audio = '../../Beatbox_Set'\n",
    "\n",
    "list_wav = []\n",
    "list_csv_1 = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv_1.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv_1[:14])\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "                Classes_All = np.zeros(1)\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets_ref = onsets_samples.astype(int)\n",
    "\n",
    "                for k in range(10):\n",
    "\n",
    "                    Classes = []\n",
    "                    labels = np.genfromtxt(list_csv[i], dtype='S', delimiter=',', usecols=1).tolist()\n",
    "                    for h in range(len(labels)):\n",
    "                        Classes.append(labels[h].decode(\"utf-8\"))\n",
    "                    Classes = np.array(Classes)\n",
    "\n",
    "                    Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "                    kn = np.random.randint(0,2)\n",
    "                    pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                    st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                    if kn==0:\n",
    "                        audio = pitch_shift(audio_ref, fs, pt)\n",
    "                        audio = time_stretch(audio, st)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "                    elif kn==1:\n",
    "                        audio = time_stretch(audio_ref, st)\n",
    "                        audio = pitch_shift(audio, fs, pt)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "\n",
    "                    Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    if Onsets[len(Onsets)-1]==1:\n",
    "                        Classes = Classes[:-1]\n",
    "                    if Onsets[len(Onsets)-1]==1:\n",
    "                        Onsets[len(Onsets)-1] = 0\n",
    "                        print(len(Classes))\n",
    "                        print(int(np.sum(Onsets)))\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    if num_onsets!=len(Classes):\n",
    "                        raise('num_onsets!=len(Classes)')\n",
    "                    Spec_Matrix = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    cc = 0\n",
    "                    Classes_Select = []\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            if Classes[cc]=='k' or Classes[cc]=='hc' or Classes[cc]=='ho' or Classes[cc]=='sb' or Classes[cc]=='sk' or Classes[cc]=='s':\n",
    "                                Classes_Select.append(Classes[cc])\n",
    "                                c = 1\n",
    "                                while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                                    c += 1\n",
    "                                Spec = Dataset_Spec[n:n+c]\n",
    "                                if c<num_frames:\n",
    "                                    Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                                elif c>=num_frames:\n",
    "                                    Spec = Spec[:num_frames]\n",
    "                                Spec_Matrix = np.vstack((Spec_Matrix,np.expand_dims(Spec,axis=0)))\n",
    "                                count += 1\n",
    "                            cc += 1\n",
    "\n",
    "                    Spec_Matrix = Spec_Matrix[1:]\n",
    "\n",
    "                    if Spec_Matrix.shape[0]==len(Classes_Select):\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                        Classes_All = np.concatenate((Classes_All,Classes_Select))\n",
    "                    else:\n",
    "                        print('Cuidao')\n",
    "                        print(Spec_Matrix_All.shape)\n",
    "                        print(Classes_All.shape)\n",
    "\n",
    "                Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "                Classes_All = Classes_All[1:]\n",
    "\n",
    "                if i<=9:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix_All)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_Aug_0' + str(i) + '_' + str(hop_size), Classes_All)\n",
    "                else:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix_All)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_Aug_' + str(i) + '_' + str(hop_size), Classes_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BTX Aug Dataset (but with the typical 689 of hop size)\n",
    "\n",
    "frame_sizes = [1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_sizes = [689]\n",
    "delta_bool = False\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]\n",
    "\n",
    "Dataset_Str = 'BTX'\n",
    "\n",
    "path_audio = '../../Beatbox_Set'\n",
    "\n",
    "list_wav = []\n",
    "list_csv_1 = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv_1.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv_1[:14])\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "                Classes_All = np.zeros(1)\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets_ref = onsets_samples.astype(int)\n",
    "\n",
    "                for k in range(10):\n",
    "\n",
    "                    Classes = []\n",
    "                    labels = np.genfromtxt(list_csv[i], dtype='S', delimiter=',', usecols=1).tolist()\n",
    "                    for h in range(len(labels)):\n",
    "                        Classes.append(labels[h].decode(\"utf-8\"))\n",
    "                    Classes = np.array(Classes)\n",
    "\n",
    "                    Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "                    kn = np.random.randint(0,2)\n",
    "                    pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                    st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                    if kn==0:\n",
    "                        audio = pitch_shift(audio_ref, fs, pt)\n",
    "                        audio = time_stretch(audio, st)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "                    elif kn==1:\n",
    "                        audio = time_stretch(audio_ref, st)\n",
    "                        audio = pitch_shift(audio, fs, pt)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "\n",
    "                    Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    if Onsets[len(Onsets)-1]==1:\n",
    "                        Classes = Classes[:-1]\n",
    "                    if Onsets[len(Onsets)-1]==1:\n",
    "                        Onsets[len(Onsets)-1] = 0\n",
    "                        print(len(Classes))\n",
    "                        print(int(np.sum(Onsets)))\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    if num_onsets!=len(Classes):\n",
    "                        raise('num_onsets!=len(Classes)')\n",
    "                    Spec_Matrix = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    cc = 0\n",
    "                    Classes_Select = []\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            if Classes[cc]=='k' or Classes[cc]=='hc' or Classes[cc]=='ho' or Classes[cc]=='sb' or Classes[cc]=='sk' or Classes[cc]=='s':\n",
    "                                Classes_Select.append(Classes[cc])\n",
    "                                c = 1\n",
    "                                while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                                    c += 1\n",
    "                                Spec = Dataset_Spec[n:n+c]\n",
    "                                if c<num_frames:\n",
    "                                    Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                                elif c>=num_frames:\n",
    "                                    Spec = Spec[:num_frames]\n",
    "                                Spec_Matrix = np.vstack((Spec_Matrix,np.expand_dims(Spec,axis=0)))\n",
    "                                count += 1\n",
    "                            cc += 1\n",
    "\n",
    "                    Spec_Matrix = Spec_Matrix[1:]\n",
    "\n",
    "                    if Spec_Matrix.shape[0]==len(Classes_Select):\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                        Classes_All = np.concatenate((Classes_All,Classes_Select))\n",
    "                    else:\n",
    "                        print('Cuidao')\n",
    "                        print(Spec_Matrix_All.shape)\n",
    "                        print(Classes_All.shape)\n",
    "\n",
    "                Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "                Classes_All = Classes_All[1:]\n",
    "\n",
    "                if i<=9:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_Aug_0' + str(i), Classes_All)\n",
    "                else:\n",
    "                    np.save('../_Data/UC_BTX/Dataset_BTX_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                    np.save('../_Data/UC_BTX/Classes_BTX_Aug_' + str(i), Classes_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_BTX/Dataset_BTX_Aug_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_BTX/Classes_BTX_Aug_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets = ['AVP_Personal_TRAIN_AUG_','AVP_Fixed_Small','LVT_2','LVT_3','BTX','VIM']\n",
    "\n",
    "frame_sizes = [1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_size = 689\n",
    "delta_bool = False\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_1 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT1'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('1.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Train_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Train_0' + str(i), Classes)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Train_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Train_' + str(i), Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_LVT/Dataset_1_Train_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_LVT/Classes_1_Train_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_1 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT1'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('1.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Train_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Train_0' + str(i), Classes)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Train_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Train_' + str(i), Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_2 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT2'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('2.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Train_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Train_0' + str(i), Classes)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Train_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Train_' + str(i), Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_3 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT3'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('3.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Train_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Train_0' + str(i), Classes)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Train_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Train_' + str(i), Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_1 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT1'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('1.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[20:]\n",
    "list_csv = list_csv[20:]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "            Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "            Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "            Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Test_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Test_0' + str(i), Classes)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_1_Test_0' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_1_Test_0' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_1_Test_0' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_1_Test_0' + str(i), Nucleus_Phonemes_Reduced_Labels)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Test_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Test_' + str(i), Classes)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_1_Test_' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_1_Test_' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_1_Test_' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_1_Test_' + str(i), Nucleus_Phonemes_Reduced_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_LVT/Dataset_1_Test_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_LVT/Classes_1_Test_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_2 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT2'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('2.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[20:]\n",
    "list_csv = list_csv[20:]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "            Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "            Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "            Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Test_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Test_0' + str(i), Classes)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_2_Test_0' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_2_Test_0' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_2_Test_0' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_2_Test_0' + str(i), Nucleus_Phonemes_Reduced_Labels)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Test_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Test_' + str(i), Classes)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_2_Test_' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_2_Test_' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_2_Test_' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_2_Test_' + str(i), Nucleus_Phonemes_Reduced_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_3 Dataset\n",
    "\n",
    "Dataset_Str = 'LVT3'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('3.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[20:]\n",
    "list_csv = list_csv[20:]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "            Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "            Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "            Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "                \n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Test_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Test_0' + str(i), Classes)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_3_Test_0' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_3_Test_0' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_3_Test_0' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_3_Test_0' + str(i), Nucleus_Phonemes_Reduced_Labels)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Test_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Test_' + str(i), Classes)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_3_Test_' + str(i), Onset_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_3_Test_' + str(i), Nucleus_Phonemes_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_3_Test_' + str(i), Onset_Phonemes_Reduced_Labels)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_3_Test_' + str(i), Nucleus_Phonemes_Reduced_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_1 Aug Dataset\n",
    "\n",
    "Dataset_Str = 'LVT1'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('1.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "            \n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:]   \n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Train_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Train_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_1_Train_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_1_Train_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_1_Train_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_1_Train_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Train_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Train_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_1_Train_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_1_Train_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_1_Train_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_1_Train_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_LVT/Dataset_1_Train_Aug_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_LVT/Classes_1_Train_Aug_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_2 Aug Dataset\n",
    "\n",
    "Dataset_Str = 'LVT2'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('2.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:] \n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Train_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Train_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_2_Train_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_2_Train_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_2_Train_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_2_Train_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Train_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Train_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_2_Train_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_2_Train_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_2_Train_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_2_Train_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_3 Aug Dataset\n",
    "\n",
    "Dataset_Str = 'LVT3'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('3.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[:20]\n",
    "list_csv = list_csv[:20]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "                \n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:] \n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Train_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Train_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_3_Train_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_3_Train_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_3_Train_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_3_Train_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Train_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Train_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_3_Train_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_3_Train_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_3_Train_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_3_Train_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_1 Aug Dataset\n",
    "\n",
    "Dataset_Str = 'LVT1'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('1.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[20:]\n",
    "list_csv = list_csv[20:]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:] \n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Test_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Test_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_1_Test_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_1_Test_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_1_Test_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_1_Test_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_1_Test_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_1_Test_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_1_Test_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_1_Test_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_1_Test_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_1_Test_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    Dataset_Spec = np.load('../_Data/UC_LVT/Dataset_1_Test_Aug_0' + str(i) + '_' + str(64) + '_' + str(1024) + '.npy')\n",
    "    Classes = np.load('../_Data/UC_LVT/Classes_1_Test_Aug_0' + str(i) + '.npy')\n",
    "    \n",
    "    print(Dataset_Spec.shape)\n",
    "    print(Classes.shape)\n",
    "\n",
    "    if i%2==0:\n",
    "        \n",
    "        Spec = Dataset_Spec[-3]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-3])\n",
    "        \n",
    "        Spec = Dataset_Spec[-2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-2])\n",
    "        \n",
    "        Spec = Dataset_Spec[-1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[-1])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Spec = Dataset_Spec[0]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[0])\n",
    "        \n",
    "        Spec = Dataset_Spec[1]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[1])\n",
    "        \n",
    "        Spec = Dataset_Spec[2]\n",
    "        Spec = (Spec-np.min(Spec))/(np.max(Spec)-np.min(Spec)+1e-16)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(Spec)\n",
    "        plt.show()\n",
    "        print(Classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_2 Aug Dataset\n",
    "\n",
    "Dataset_Str = 'LVT2'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('2.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[20:]\n",
    "list_csv = list_csv[20:]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:] \n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Test_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Test_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_2_Test_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_2_Test_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_2_Test_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_2_Test_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_2_Test_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_2_Test_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_2_Test_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_2_Test_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_2_Test_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_2_Test_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LVT_3 Aug Dataset\n",
    "\n",
    "Dataset_Str = 'LVT3'\n",
    "\n",
    "path_audio = '../../LVT_Dataset/DataSet_Wav_Annotation'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('3.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav = list_wav[20:]\n",
    "list_csv = list_csv[20:]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "            \n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "            Classes_All = np.zeros(1)\n",
    "            Onset_Phonemes_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Labels_All = np.zeros(1)\n",
    "            Onset_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = np.zeros(1)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                Classes = np.loadtxt(list_csv[i], delimiter=',', usecols=1, dtype=np.unicode_)\n",
    "                Onset_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=2, dtype=np.unicode_)\n",
    "                Nucleus_Phonemes = np.loadtxt(list_csv[i], delimiter=',', usecols=3, dtype=np.unicode_)\n",
    "\n",
    "                Onset_Phonemes_Labels, Nucleus_Phonemes_Labels, Onset_Phonemes_Reduced_Labels, Nucleus_Phonemes_Reduced_Labels = Create_Phoneme_Labels(Onset_Phonemes, Nucleus_Phonemes)\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "                Classes_All = np.concatenate((Classes_All,Classes))\n",
    "                Onset_Phonemes_Labels_All = np.concatenate((Onset_Phonemes_Labels_All,Onset_Phonemes_Labels))\n",
    "                Nucleus_Phonemes_Labels_All = np.concatenate((Nucleus_Phonemes_Labels_All,Nucleus_Phonemes_Labels))\n",
    "                Onset_Phonemes_Reduced_Labels_All = np.concatenate((Onset_Phonemes_Reduced_Labels_All,Onset_Phonemes_Reduced_Labels))\n",
    "                Nucleus_Phonemes_Reduced_Labels_All = np.concatenate((Nucleus_Phonemes_Reduced_Labels_All,Nucleus_Phonemes_Reduced_Labels))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "            Classes_All = Classes_All[1:]\n",
    "            Onset_Phonemes_Labels_All = Onset_Phonemes_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Labels_All = Nucleus_Phonemes_Labels_All[1:]\n",
    "            Onset_Phonemes_Reduced_Labels_All = Onset_Phonemes_Reduced_Labels_All[1:]\n",
    "            Nucleus_Phonemes_Reduced_Labels_All = Nucleus_Phonemes_Reduced_Labels_All[1:] \n",
    "\n",
    "            if i<=9:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Test_Aug_0' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Test_Aug_0' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_3_Test_Aug_0' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_3_Test_Aug_0' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_3_Test_Aug_0' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_3_Test_Aug_0' + str(i), Nucleus_Phonemes_Reduced_Labels_All)\n",
    "            else:\n",
    "                np.save('../_Data/UC_LVT/Dataset_3_Test_Aug_' + str(i) + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "                np.save('../_Data/UC_LVT/Classes_3_Test_Aug_' + str(i), Classes_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_3_Test_Aug_' + str(i), Onset_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_3_Test_Aug_' + str(i), Nucleus_Phonemes_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Onset_Reduced_3_Test_Aug_' + str(i), Onset_Phonemes_Reduced_Labels_All)\n",
    "                np.save('../_Data/UC_LVT/Syll_Nucleus_Reduced_3_Test_Aug_' + str(i), Nucleus_Phonemes_Reduced_Labels_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VIM_Percussive Dataset\n",
    "\n",
    "Dataset_Str = 'VIM_Percussive'\n",
    "\n",
    "path_audio = '../../VIM_Percussive_Dataset'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            if onsets.ndim==0:\n",
    "\n",
    "                location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                Spec = Dataset_Spec[location:]\n",
    "                if Spec.shape[0]<num_frames:\n",
    "                    Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                elif Spec.shape[0]>=num_frames:\n",
    "                    Spec = Spec[:num_frames]\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "            else:\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while Onsets[n+c]==0 and (n+c)<L-1:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_VIM/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VIM_Percussive Aug Dataset\n",
    "\n",
    "Dataset_Str = 'VIM_Percussive_Aug'\n",
    "\n",
    "path_audio = '../../VIM_Percussive_Dataset'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            \n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                if onsets.ndim==0:\n",
    "\n",
    "                    location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                    Spec = Dataset_Spec[location:]\n",
    "                    if Spec.shape[0]<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                    elif Spec.shape[0]>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "                else:\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            c = 1\n",
    "                            while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix[count] = Spec\n",
    "                            count += 1\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_VIM/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AVP_Fixed_Small Dataset\n",
    "\n",
    "Dataset_Str = 'AVP_Fixed_Small'\n",
    "\n",
    "path_audio = '../../AVP_Dataset/Fixed'\n",
    "\n",
    "# Load Files\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "list_wav = list_wav[2::5]\n",
    "list_csv = list_csv[2::5]\n",
    "\n",
    "list_wav = list_wav[::2]\n",
    "list_csv = list_csv[::2]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets = onsets_samples.astype(int)\n",
    "\n",
    "            Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "            Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "            location = np.floor(onsets/hop_size)\n",
    "            if (location.astype(int)[-1]<len(Onsets)):\n",
    "                Onsets[location.astype(int)] = 1\n",
    "            else:\n",
    "                Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "            num_onsets = int(np.sum(Onsets))\n",
    "            Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "            L = len(Onsets)\n",
    "            count = 0\n",
    "            for n in range(L):\n",
    "                if Onsets[n]==1:\n",
    "                    c = 1\n",
    "                    while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                        c += 1\n",
    "                    Spec = Dataset_Spec[n:n+c]\n",
    "                    if c<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                    elif c>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "                    Spec_Matrix[count] = Spec\n",
    "                    count += 1\n",
    "\n",
    "            Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_AVPFS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AVP_Fixed_Small Dataset\n",
    "\n",
    "Dataset_Str = 'AVP_Fixed_Small_Aug'\n",
    "\n",
    "path_audio = '../../AVP_Dataset/Fixed'\n",
    "\n",
    "# Load Files\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "list_wav.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "list_csv.sort(key = lambda f:int(''.join(filter(str.isdigit,f))))\n",
    "\n",
    "list_wav = list_wav[2::5]\n",
    "list_csv = list_csv[2::5]\n",
    "\n",
    "list_wav = list_wav[::2]\n",
    "list_csv = list_csv[::2]\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                location = np.floor(onsets/hop_size)\n",
    "                if (location.astype(int)[-1]<len(Onsets)):\n",
    "                    Onsets[location.astype(int)] = 1\n",
    "                else:\n",
    "                    Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                num_onsets = int(np.sum(Onsets))\n",
    "                Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                L = len(Onsets)\n",
    "                count = 0\n",
    "                for n in range(L):\n",
    "                    if Onsets[n]==1:\n",
    "                        c = 1\n",
    "                        while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                            c += 1\n",
    "                        Spec = Dataset_Spec[n:n+c]\n",
    "                        if c<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                        elif c>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "                        Spec_Matrix[count] = Spec\n",
    "                        count += 1\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_AVPFS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FSB_Multi Aug Dataset\n",
    "\n",
    "Dataset_Str = 'FSB_Multi_Aug'\n",
    "\n",
    "path_audio = '../../FSB_Dataset/Multi'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                if onsets.ndim==0:\n",
    "\n",
    "                    location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                    Spec = Dataset_Spec[location:]\n",
    "                    if Spec.shape[0]<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                    elif Spec.shape[0]>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "                else:\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            c = 1\n",
    "                            while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix[count] = Spec\n",
    "                            count += 1\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_FSB/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FSB_Single Aug Dataset\n",
    "\n",
    "Dataset_Str = 'FSB_Single_Aug'\n",
    "\n",
    "path_audio = '../../FSB_Dataset/Single'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            if len(audio)<frame_size:\n",
    "                continue\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_ref = int(onsets*fs)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    #onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    #onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                Spec = Dataset_Spec[location:]\n",
    "                if Spec.shape[0]<num_frames:\n",
    "                    Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                elif Spec.shape[0]>=num_frames:\n",
    "                    Spec = Spec[:num_frames]\n",
    "\n",
    "                Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_FSB/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BTX_SS\n",
    "\n",
    "frame_sizes = [256,512,1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_sizes = [220,413]\n",
    "delta_bool = False\n",
    "\n",
    "Dataset_Str = 'FSB_Multi' # Selected FSB_Multi Aug\n",
    "\n",
    "path_audio = '../../Beatbox_SS/Multi'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_samples = onsets*fs\n",
    "                onsets_ref = onsets_samples.astype(int)\n",
    "\n",
    "                for k in range(10):\n",
    "\n",
    "                    kn = np.random.randint(0,2)\n",
    "                    pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                    st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                    if kn==0:\n",
    "                        audio = pitch_shift(audio_ref, fs, pt)\n",
    "                        audio = time_stretch(audio, st)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "                    elif kn==1:\n",
    "                        audio = time_stretch(audio_ref, st)\n",
    "                        audio = pitch_shift(audio, fs, pt)\n",
    "                        onsets = onsets_ref/st\n",
    "                        onsets = onsets.astype(int)\n",
    "\n",
    "                    Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                    if onsets.ndim==0:\n",
    "\n",
    "                        location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                        Spec = Dataset_Spec[location:]\n",
    "                        if Spec.shape[0]<num_frames:\n",
    "                            Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                        elif Spec.shape[0]>=num_frames:\n",
    "                            Spec = Spec[:num_frames]\n",
    "\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                        location = np.floor(onsets/hop_size)\n",
    "                        if (location.astype(int)[-1]<len(Onsets)):\n",
    "                            Onsets[location.astype(int)] = 1\n",
    "                        else:\n",
    "                            Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                        num_onsets = int(np.sum(Onsets))\n",
    "                        Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                        L = len(Onsets)\n",
    "                        count = 0\n",
    "                        for n in range(L):\n",
    "                            if Onsets[n]==1:\n",
    "                                c = 1\n",
    "                                while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                                    c += 1\n",
    "                                Spec = Dataset_Spec[n:n+c]\n",
    "                                if c<num_frames:\n",
    "                                    Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                                elif c>=num_frames:\n",
    "                                    Spec = Spec[:num_frames]\n",
    "                                Spec_Matrix[count] = Spec\n",
    "                                count += 1\n",
    "\n",
    "                        Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "            np.save('../_Data/UC_BTX_SS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix_All)\n",
    "\n",
    "Dataset_Str = 'FSB_Single' # Selected FSB_Single Aug\n",
    "\n",
    "path_audio = '../../Beatbox_SS/Single'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                if len(audio)<frame_size:\n",
    "                    continue\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_ref = int(onsets*fs)\n",
    "\n",
    "                for k in range(10):\n",
    "\n",
    "                    kn = np.random.randint(0,2)\n",
    "                    pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                    st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                    if kn==0:\n",
    "                        audio = pitch_shift(audio_ref, fs, pt)\n",
    "                        audio = time_stretch(audio, st)\n",
    "                        onsets = onsets_ref/st\n",
    "                        #onsets = onsets.astype(int)\n",
    "                    elif kn==1:\n",
    "                        audio = time_stretch(audio_ref, st)\n",
    "                        audio = pitch_shift(audio, fs, pt)\n",
    "                        onsets = onsets_ref/st\n",
    "                        #onsets = onsets.astype(int)\n",
    "\n",
    "                    Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                    location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                    Spec = Dataset_Spec[location:]\n",
    "                    if Spec.shape[0]<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                    elif Spec.shape[0]>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "            np.save('../_Data/UC_BTX_SS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_sizes = [256,512,1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_sizes = [220,413]\n",
    "delta_bool = False\n",
    "\n",
    "Dataset_Str = 'FSB_Single' # Selected FSB_Single Aug\n",
    "\n",
    "path_audio = '../../Beatbox_SS/Single'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for w in range(len(hop_sizes)):\n",
    "\n",
    "    for j in range(len(num_specs)):\n",
    "\n",
    "        for k in range(len(frame_sizes)):\n",
    "\n",
    "            frame_size = frame_sizes[k]\n",
    "            num_spec = num_specs[j]\n",
    "            hop_size = hop_sizes[w]\n",
    "\n",
    "            Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "            for i in range(len(list_wav)):\n",
    "\n",
    "                onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "                audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "                if len(audio)<frame_size:\n",
    "                    continue\n",
    "                audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "                onsets_ref = int(onsets*fs)\n",
    "\n",
    "                for k in range(10):\n",
    "\n",
    "                    kn = np.random.randint(0,2)\n",
    "                    pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                    st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                    if kn==0:\n",
    "                        audio = pitch_shift(audio_ref, fs, pt)\n",
    "                        audio = time_stretch(audio, st)\n",
    "                        onsets = onsets_ref/st\n",
    "                        #onsets = onsets.astype(int)\n",
    "                    elif kn==1:\n",
    "                        audio = time_stretch(audio_ref, st)\n",
    "                        audio = pitch_shift(audio, fs, pt)\n",
    "                        onsets = onsets_ref/st\n",
    "                        #onsets = onsets.astype(int)\n",
    "\n",
    "                    Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                    location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                    Spec = Dataset_Spec[location:]\n",
    "                    if Spec.shape[0]<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                    elif Spec.shape[0]>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "            Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "            np.save('../_Data/UC_BTX_SS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size) + '_' + str(hop_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AVP_LVT_SS\n",
    "\n",
    "frame_sizes = [1024,2048,4096]\n",
    "num_specs = [64]\n",
    "num_frames = 32\n",
    "\n",
    "hop_size = 689\n",
    "delta_bool = False\n",
    "\n",
    "pitch = [-1,1]\n",
    "times = [0.85,1.15]\n",
    "\n",
    "Dataset_Str = 'VIM_Percussive'\n",
    "\n",
    "path_audio = '../../Amateur_SS/VIM_Percussive'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "            \n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            for k in range(10):\n",
    "                \n",
    "                kn = np.random.randint(0,2)\n",
    "                pt = np.random.uniform(low=-1.5, high=1.5, size=None)\n",
    "                st = np.random.uniform(low=0.8, high=1.2, size=None)\n",
    "\n",
    "                if kn==0:\n",
    "                    audio = pitch_shift(audio_ref, fs, pt)\n",
    "                    audio = time_stretch(audio, st)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif kn==1:\n",
    "                    audio = time_stretch(audio_ref, st)\n",
    "                    audio = pitch_shift(audio, fs, pt)\n",
    "                    onsets = onsets_ref/st\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                if onsets.ndim==0:\n",
    "\n",
    "                    location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                    Spec = Dataset_Spec[location:]\n",
    "                    if Spec.shape[0]<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                    elif Spec.shape[0]>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "                else:\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            c = 1\n",
    "                            while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix[count] = Spec\n",
    "                            count += 1\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_AVP_LVT_SS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)\n",
    "\n",
    "Dataset_Str = 'FSB_Multi'\n",
    "\n",
    "path_audio = '../../Amateur_SS/Multi'\n",
    "\n",
    "list_wav = []\n",
    "list_csv = []\n",
    "\n",
    "for path, subdirs, files in os.walk(path_audio):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            list_wav.append(os.path.join(path, filename))\n",
    "        if filename.endswith('.csv'):\n",
    "            list_csv.append(os.path.join(path, filename))\n",
    "\n",
    "list_wav = sorted(list_wav)\n",
    "list_csv = sorted(list_csv)\n",
    "\n",
    "for j in range(len(num_specs)):\n",
    "    \n",
    "    for k in range(len(frame_sizes)):\n",
    "\n",
    "        frame_size = frame_sizes[k]\n",
    "        num_spec = num_specs[j]\n",
    "\n",
    "        Spec_Matrix_All = np.zeros((1,num_frames,num_spec))\n",
    "\n",
    "        for i in range(len(list_wav)):\n",
    "\n",
    "            onsets = np.loadtxt(list_csv[i], delimiter=',', usecols=0)\n",
    "\n",
    "            audio, fs = librosa.load(list_wav[i], sr=44100)\n",
    "            audio_ref = audio/np.max(abs(audio))\n",
    "\n",
    "            onsets_samples = onsets*fs\n",
    "            onsets_ref = onsets_samples.astype(int)\n",
    "            \n",
    "            for k in range(10):\n",
    "\n",
    "                if k==0:\n",
    "                    audio = audio_ref.copy()\n",
    "                    onsets = onsets_ref.copy()\n",
    "                elif k==1:\n",
    "                    audio = pitch_shift(audio_ref, fs, pitch[0])\n",
    "                    onsets = onsets_ref.copy()\n",
    "                elif k==2:\n",
    "                    audio = pitch_shift(audio_ref, fs, pitch[1])\n",
    "                    onsets = onsets_ref.copy()\n",
    "                elif k==3:\n",
    "                    audio = time_stretch(audio_ref, times[0])\n",
    "                    onsets = onsets_ref/times[0]\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif k==4:\n",
    "                    audio = time_stretch(audio_ref, times[1])\n",
    "                    onsets = onsets_ref/times[1]\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif k==5:\n",
    "                    audio = pitch_shift(audio_ref, fs, pitch[0])\n",
    "                    audio = time_stretch(audio, times[0])\n",
    "                    onsets = onsets_ref/times[0]\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif k==6:\n",
    "                    audio = pitch_shift(audio_ref, fs, pitch[0])\n",
    "                    audio = time_stretch(audio, times[1])\n",
    "                    onsets = onsets_ref/times[1]\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif k==7:\n",
    "                    audio = pitch_shift(audio_ref, fs, pitch[1])\n",
    "                    audio = time_stretch(audio, times[0])\n",
    "                    onsets = onsets_ref/times[0]\n",
    "                    onsets = onsets.astype(int)\n",
    "                elif k==8:\n",
    "                    audio = pitch_shift(audio_ref, fs, pitch[1])\n",
    "                    audio = time_stretch(audio, times[1])\n",
    "                    onsets = onsets_ref/times[1]\n",
    "                    onsets = onsets.astype(int)\n",
    "\n",
    "                Dataset_Spec = librosa.feature.melspectrogram(audio, sr=44100, n_fft=frame_size, hop_length=hop_size, n_mels=num_spec, power=1.0).T\n",
    "\n",
    "                if onsets.ndim==0:\n",
    "\n",
    "                    location = int(np.floor(onsets/hop_size))\n",
    "\n",
    "                    Spec = Dataset_Spec[location:]\n",
    "                    if Spec.shape[0]<num_frames:\n",
    "                        Spec = np.concatenate((Spec,np.zeros((num_frames-Spec.shape[0],num_spec))))\n",
    "                    elif Spec.shape[0]>=num_frames:\n",
    "                        Spec = Spec[:num_frames]\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,np.expand_dims(Spec,axis=0)))\n",
    "\n",
    "                else:\n",
    "\n",
    "                    Onsets = np.zeros(Dataset_Spec.shape[0])\n",
    "                    location = np.floor(onsets/hop_size)\n",
    "                    if (location.astype(int)[-1]<len(Onsets)):\n",
    "                        Onsets[location.astype(int)] = 1\n",
    "                    else:\n",
    "                        Onsets[location.astype(int)[:-1]] = 1\n",
    "\n",
    "                    num_onsets = int(np.sum(Onsets))\n",
    "                    Spec_Matrix = np.zeros((num_onsets,num_frames,num_spec))\n",
    "\n",
    "                    L = len(Onsets)\n",
    "                    count = 0\n",
    "                    for n in range(L):\n",
    "                        if Onsets[n]==1:\n",
    "                            c = 1\n",
    "                            while (n+c)<L-1 and Onsets[n+c]==0:\n",
    "                                c += 1\n",
    "                            Spec = Dataset_Spec[n:n+c]\n",
    "                            if c<num_frames:\n",
    "                                Spec = np.concatenate((Spec,np.zeros((num_frames-c,num_spec))))\n",
    "                            elif c>=num_frames:\n",
    "                                Spec = Spec[:num_frames]\n",
    "                            Spec_Matrix[count] = Spec\n",
    "                            count += 1\n",
    "\n",
    "                    Spec_Matrix_All = np.vstack((Spec_Matrix_All,Spec_Matrix))\n",
    "\n",
    "        Spec_Matrix_All = Spec_Matrix_All[1:]\n",
    "\n",
    "        np.save('../_Data/UC_AVP_LVT_SS/Dataset_' + Dataset_Str + '_' + str(num_spec) + '_' + str(frame_size), Spec_Matrix_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mip",
   "language": "python",
   "name": "mip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
